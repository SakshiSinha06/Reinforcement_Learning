{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OybTzT6JjFKa"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpilf7Uui4Fr",
        "outputId": "eaeae2f5-682f-4eda-e5cc-14262cba4c21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.8.0+cu126)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (4.12.0.88)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.19.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (0.11.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (11.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3[extra]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.75.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.9)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->stable-baselines3[extra]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->stable-baselines3[extra]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMh5OAXuj-4j",
        "outputId": "97e20b68-a75c-4c0b-c859-f0b22a245fd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: swig in /usr/local/lib/python3.12/dist-packages (4.3.1.post0)\n"
          ]
        }
      ],
      "source": [
        "!pip install swig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bds6jsPRk9hO",
        "outputId": "3154c55d-d60d-4367-ecc5-2c4161c745c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.3.5)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (4.3.1.post0)\n"
          ]
        }
      ],
      "source": [
        "!pip install 'gymnasium[box2d]'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9L9JfdDQe_KC"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "import os\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback, CallbackList"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLidzGeZjLll"
      },
      "source": [
        "# Test Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9YS4JAMkfbh",
        "outputId": "f6a8aa24-11dc-436a-aaf0-1eb1c660cca2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== classic_control =====\n",
            "Acrobot-v1             CartPole-v0            CartPole-v1\n",
            "MountainCar-v0         MountainCarContinuous-v0 Pendulum-v1\n",
            "===== phys2d =====\n",
            "phys2d/CartPole-v0     phys2d/CartPole-v1     phys2d/Pendulum-v0\n",
            "===== box2d =====\n",
            "BipedalWalker-v3       BipedalWalkerHardcore-v3 CarRacing-v3\n",
            "LunarLander-v3         LunarLanderContinuous-v3\n",
            "===== toy_text =====\n",
            "Blackjack-v1           CliffWalking-v1        CliffWalkingSlippery-v1\n",
            "FrozenLake-v1          FrozenLake8x8-v1       Taxi-v3\n",
            "===== tabular =====\n",
            "tabular/Blackjack-v0   tabular/CliffWalking-v0\n",
            "===== None =====\n",
            "Ant-v2                 Ant-v3                 GymV21Environment-v0\n",
            "GymV26Environment-v0   HalfCheetah-v2         HalfCheetah-v3\n",
            "Hopper-v2              Hopper-v3              Humanoid-v2\n",
            "Humanoid-v3            HumanoidStandup-v2     InvertedDoublePendulum-v2\n",
            "InvertedPendulum-v2    Pusher-v2              Reacher-v2\n",
            "Swimmer-v2             Swimmer-v3             Walker2d-v2\n",
            "Walker2d-v3\n",
            "===== mujoco =====\n",
            "Ant-v4                 Ant-v5                 HalfCheetah-v4\n",
            "HalfCheetah-v5         Hopper-v4              Hopper-v5\n",
            "Humanoid-v4            Humanoid-v5            HumanoidStandup-v4\n",
            "HumanoidStandup-v5     InvertedDoublePendulum-v4 InvertedDoublePendulum-v5\n",
            "InvertedPendulum-v4    InvertedPendulum-v5    Pusher-v4\n",
            "Pusher-v5              Reacher-v4             Reacher-v5\n",
            "Swimmer-v4             Swimmer-v5             Walker2d-v4\n",
            "Walker2d-v5\n"
          ]
        }
      ],
      "source": [
        "gym.pprint_registry()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdvlPvKkl66M"
      },
      "outputs": [],
      "source": [
        "environment_name = \"CarRacing-v3\"\n",
        "env = gym.make(environment_name)\n",
        "episodes = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-hVOKvkjKzv",
        "outputId": "ef61af1a-6412-4e67-fe31-237446d49dcf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/envs/box2d/car_racing.py:592: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"CarRacing-v3\", render_mode=\"rgb_array\")\u001b[0m\n",
            "  gym.logger.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode:1 Score:-26.199261992620098\n",
            "Episode:2 Score:-35.5932203389836\n",
            "Episode:3 Score:-31.159420289855365\n",
            "Episode:4 Score:-36.50793650793711\n",
            "Episode:5 Score:-33.333333333333734\n"
          ]
        }
      ],
      "source": [
        "for episode in range(1, episodes+1):\n",
        "    state, info = env.reset() # Updated env.reset to return two values\n",
        "    done = False\n",
        "    score = 0\n",
        "\n",
        "    while not done:\n",
        "        env.render()\n",
        "        action = env.action_space.sample()\n",
        "        n_state, reward, terminated, truncated, info = env.step(action) # Unpack 5 values\n",
        "        done = terminated or truncated # Combine terminated and truncated for loop condition\n",
        "        score+=reward\n",
        "    print('Episode:{} Score:{}'.format(episode, score))\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhFMHdEVjC7V",
        "outputId": "fbcd87f7-ccb4-42de-a802-cd563c4fa3d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.8244978, 0.9612945, 0.4454341], dtype=float32)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.action_space.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "h6ZvR1-PjTZh",
        "outputId": "bc82c9ca-2049-4a74-c27a-9f5ffaa8a50f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-0f813c52-b10c-4e2e-8620-877232892024\" class=\"ndarray_repr\"><pre>ndarray (96, 96, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[ 70, 132,  26],\n",
              "        [ 49, 222, 228],\n",
              "        [ 58, 204, 183],\n",
              "        ...,\n",
              "        [156, 221, 246],\n",
              "        [135,  10, 217],\n",
              "        [ 73, 188,  13]],\n",
              "\n",
              "       [[152, 176, 178],\n",
              "        [246,  71, 127],\n",
              "        [ 45, 218,  98],\n",
              "        ...,\n",
              "        [ 89, 230, 130],\n",
              "        [103,  31, 126],\n",
              "        [155, 185, 116]],\n",
              "\n",
              "       [[187,   3,  72],\n",
              "        [  9, 224,  28],\n",
              "        [120,  94,  71],\n",
              "        ...,\n",
              "        [177,  38,  68],\n",
              "        [ 38, 154,  25],\n",
              "        [ 77, 196, 215]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[  9, 166, 220],\n",
              "        [ 34, 210, 101],\n",
              "        [ 45, 173, 111],\n",
              "        ...,\n",
              "        [103, 212, 238],\n",
              "        [218, 245, 115],\n",
              "        [133, 217,  78]],\n",
              "\n",
              "       [[ 92,  78, 151],\n",
              "        [149, 158,  98],\n",
              "        [144, 210, 243],\n",
              "        ...,\n",
              "        [191, 153,  33],\n",
              "        [ 34, 235, 129],\n",
              "        [ 59,  56,   0]],\n",
              "\n",
              "       [[234,  47, 245],\n",
              "        [140, 207,  88],\n",
              "        [207,  19,  74],\n",
              "        ...,\n",
              "        [138, 217, 184],\n",
              "        [128, 250,  95],\n",
              "        [154, 124, 134]]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-0f813c52-b10c-4e2e-8620-877232892024 button').onclick = (e) => {\n",
              "        document.querySelector('#id-0f813c52-b10c-4e2e-8620-877232892024').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-0f813c52-b10c-4e2e-8620-877232892024 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ],
            "text/plain": [
              "array([[[ 70, 132,  26],\n",
              "        [ 49, 222, 228],\n",
              "        [ 58, 204, 183],\n",
              "        ...,\n",
              "        [156, 221, 246],\n",
              "        [135,  10, 217],\n",
              "        [ 73, 188,  13]],\n",
              "\n",
              "       [[152, 176, 178],\n",
              "        [246,  71, 127],\n",
              "        [ 45, 218,  98],\n",
              "        ...,\n",
              "        [ 89, 230, 130],\n",
              "        [103,  31, 126],\n",
              "        [155, 185, 116]],\n",
              "\n",
              "       [[187,   3,  72],\n",
              "        [  9, 224,  28],\n",
              "        [120,  94,  71],\n",
              "        ...,\n",
              "        [177,  38,  68],\n",
              "        [ 38, 154,  25],\n",
              "        [ 77, 196, 215]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[  9, 166, 220],\n",
              "        [ 34, 210, 101],\n",
              "        [ 45, 173, 111],\n",
              "        ...,\n",
              "        [103, 212, 238],\n",
              "        [218, 245, 115],\n",
              "        [133, 217,  78]],\n",
              "\n",
              "       [[ 92,  78, 151],\n",
              "        [149, 158,  98],\n",
              "        [144, 210, 243],\n",
              "        ...,\n",
              "        [191, 153,  33],\n",
              "        [ 34, 235, 129],\n",
              "        [ 59,  56,   0]],\n",
              "\n",
              "       [[234,  47, 245],\n",
              "        [140, 207,  88],\n",
              "        [207,  19,  74],\n",
              "        ...,\n",
              "        [138, 217, 184],\n",
              "        [128, 250,  95],\n",
              "        [154, 124, 134]]], dtype=uint8)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.observation_space.sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHJk04PrmwA7"
      },
      "source": [
        "# Vectorise Environment and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nOdgjsblE9n"
      },
      "outputs": [],
      "source": [
        "ENV_ID = 'CarRacing-v3'\n",
        "LOG_PATH = os.path.join('Training', 'Logs', ENV_ID)\n",
        "SAVE_PATH = os.path.join('Training', 'Saved Models')\n",
        "MODEL_NAME = f'A2C_CarRacing_v3'\n",
        "TOTAL_TIMESTEPS = 20000\n",
        "EVAL_FREQ = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCNzfaw_mzG8",
        "outputId": "88d6fa37-5bfd-4d8f-ec30-b524cf9ebe85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env in a VecTransposeImage.\n"
          ]
        }
      ],
      "source": [
        "env = DummyVecEnv([lambda: gym.make(ENV_ID)])\n",
        "\n",
        "model = A2C(\"CnnPolicy\",\n",
        "            env,\n",
        "            verbose=1,\n",
        "            tensorboard_log=LOG_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdX0bJm1zOPD"
      },
      "outputs": [],
      "source": [
        "checkpoint_cb = CheckpointCallback(\n",
        "    save_freq=EVAL_FREQ,\n",
        "    save_path=SAVE_PATH,\n",
        "    name_prefix='a2c_checkpoint'\n",
        ")\n",
        "\n",
        "eval_env = DummyVecEnv([lambda: gym.make(ENV_ID, render_mode=\"rgb_array\")])\n",
        "\n",
        "eval_cb = EvalCallback(\n",
        "    eval_env,\n",
        "    best_model_save_path=os.path.join(SAVE_PATH, 'best_model'), # Where to save the BEST model\n",
        "    log_path=LOG_PATH,\n",
        "    eval_freq=EVAL_FREQ,\n",
        "    deterministic=True,\n",
        "    render=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks_list = CallbackList([checkpoint_cb, eval_cb])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmUEUOIDnAtH",
        "outputId": "cc4dbe8f-0a0f-4cde-ed39-94cc42d758f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training on CarRacing-v3 for 20000 steps...\n",
            "Logging to Training/Logs/CarRacing-v3/A2C_3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x78425b6710a0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x78425b671f10>\n",
            "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 40       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.25    |\n",
            "|    explained_variance | 0.0267   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 0.289    |\n",
            "|    std                | 0.997    |\n",
            "|    value_loss         | 0.00801  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval num_timesteps=1000, episode_reward=-93.42 +/- 0.10\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -93.4    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.24    |\n",
            "|    explained_variance | 0.0396   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | 0.124    |\n",
            "|    std                | 0.995    |\n",
            "|    value_loss         | 0.00116  |\n",
            "------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 9    |\n",
            "|    iterations      | 200  |\n",
            "|    time_elapsed    | 104  |\n",
            "|    total_timesteps | 1000 |\n",
            "-----------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 12       |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 116      |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.26    |\n",
            "|    explained_variance | 0.0166   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 0.149    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.00207  |\n",
            "------------------------------------\n",
            "Eval num_timesteps=2000, episode_reward=-92.77 +/- 0.33\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -92.8    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.27    |\n",
            "|    explained_variance | 0.121    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 0.0117   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 1.07e-05 |\n",
            "------------------------------------\n",
            "New best mean reward!\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 9    |\n",
            "|    iterations      | 400  |\n",
            "|    time_elapsed    | 209  |\n",
            "|    total_timesteps | 2000 |\n",
            "-----------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 11       |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 222      |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.28    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 0.181    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.0036   |\n",
            "------------------------------------\n",
            "Eval num_timesteps=3000, episode_reward=-92.99 +/- 0.44\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -93      |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.29    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | -0.097   |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.000462 |\n",
            "------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 9    |\n",
            "|    iterations      | 600  |\n",
            "|    time_elapsed    | 314  |\n",
            "|    total_timesteps | 3000 |\n",
            "-----------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 10       |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 327      |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.28    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | -0.125   |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.00141  |\n",
            "------------------------------------\n",
            "Eval num_timesteps=4000, episode_reward=-93.21 +/- 0.41\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -93.2    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.28    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.0809   |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.000488 |\n",
            "------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 9    |\n",
            "|    iterations      | 800  |\n",
            "|    time_elapsed    | 420  |\n",
            "|    total_timesteps | 4000 |\n",
            "-----------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 10       |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 432      |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.27    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 0.0155   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 1.76e-05 |\n",
            "------------------------------------\n",
            "Eval num_timesteps=5000, episode_reward=-93.08 +/- 0.31\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -93.1    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.27    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -0.173   |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.000989 |\n",
            "------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 9    |\n",
            "|    iterations      | 1000 |\n",
            "|    time_elapsed    | 528  |\n",
            "|    total_timesteps | 5000 |\n",
            "-----------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 10       |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 540      |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.26    |\n",
            "|    explained_variance | 0.136    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | -0.0641  |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.000184 |\n",
            "------------------------------------\n",
            "Eval num_timesteps=6000, episode_reward=-93.13 +/- 0.25\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -93.1    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.28    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 0.0741   |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.000379 |\n",
            "------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 9    |\n",
            "|    iterations      | 1200 |\n",
            "|    time_elapsed    | 633  |\n",
            "|    total_timesteps | 6000 |\n",
            "-----------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 10       |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 645      |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.3     |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | -0.128   |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.00136  |\n",
            "------------------------------------\n",
            "Eval num_timesteps=7000, episode_reward=-93.02 +/- 0.37\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-------------------------------------\n",
            "| eval/                 |           |\n",
            "|    mean_ep_length     | 1e+03     |\n",
            "|    mean_reward        | -93       |\n",
            "| time/                 |           |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.31     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 0.0803    |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.000336  |\n",
            "-------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 9    |\n",
            "|    iterations      | 1400 |\n",
            "|    time_elapsed    | 740  |\n",
            "|    total_timesteps | 7000 |\n",
            "-----------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 9         |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 752       |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.31     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 0.105     |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.00075   |\n",
            "-------------------------------------\n",
            "Eval num_timesteps=8000, episode_reward=-93.10 +/- 0.43\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -93.1    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.32    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.0983   |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.000476 |\n",
            "------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 9    |\n",
            "|    iterations      | 1600 |\n",
            "|    time_elapsed    | 850  |\n",
            "|    total_timesteps | 8000 |\n",
            "-----------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 9        |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 862      |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.32    |\n",
            "|    explained_variance | -0.0042  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | -0.124   |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.000915 |\n",
            "------------------------------------\n",
            "Eval num_timesteps=9000, episode_reward=-93.33 +/- 0.67\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -93.3    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.33    |\n",
            "|    explained_variance | -0.00751 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | -0.149   |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.000999 |\n",
            "------------------------------------\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 9    |\n",
            "|    iterations      | 1800 |\n",
            "|    time_elapsed    | 956  |\n",
            "|    total_timesteps | 9000 |\n",
            "-----------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 9        |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 968      |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.33    |\n",
            "|    explained_variance | 0.0407   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 0.0238   |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 5.83e-05 |\n",
            "------------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=-93.66 +/- 0.36\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -93.7    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.33    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 0.0463   |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.000168 |\n",
            "------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 9     |\n",
            "|    iterations      | 2000  |\n",
            "|    time_elapsed    | 1062  |\n",
            "|    total_timesteps | 10000 |\n",
            "------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 9        |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 1074     |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.33    |\n",
            "|    explained_variance | 0.207    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | -0.0393  |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 9.8e-05  |\n",
            "------------------------------------\n",
            "Eval num_timesteps=11000, episode_reward=-83.35 +/- 1.75\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -83.3    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.33    |\n",
            "|    explained_variance | 0.145    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | -0.0782  |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.000257 |\n",
            "------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 9     |\n",
            "|    iterations      | 2200  |\n",
            "|    time_elapsed    | 1172  |\n",
            "|    total_timesteps | 11000 |\n",
            "------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 9        |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 1185     |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.3     |\n",
            "|    explained_variance | -0.173   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 0.0759   |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.000545 |\n",
            "------------------------------------\n",
            "Eval num_timesteps=12000, episode_reward=-22.86 +/- 15.36\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -22.9    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.31    |\n",
            "|    explained_variance | -0.743   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | -0.0456  |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.000187 |\n",
            "------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 9     |\n",
            "|    iterations      | 2400  |\n",
            "|    time_elapsed    | 1280  |\n",
            "|    total_timesteps | 12000 |\n",
            "------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 9        |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 1293     |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.31    |\n",
            "|    explained_variance | -0.651   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 0.0706   |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.000266 |\n",
            "------------------------------------\n",
            "Eval num_timesteps=13000, episode_reward=-92.49 +/- 0.29\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -92.5    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.31    |\n",
            "|    explained_variance | -0.0176  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | -0.0476  |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.000178 |\n",
            "------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 9     |\n",
            "|    iterations      | 2600  |\n",
            "|    time_elapsed    | 1385  |\n",
            "|    total_timesteps | 13000 |\n",
            "------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 9        |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 1398     |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.3     |\n",
            "|    explained_variance | 0.494    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.0422   |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.000101 |\n",
            "------------------------------------\n",
            "Eval num_timesteps=14000, episode_reward=-93.37 +/- 0.55\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -93.4    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.3     |\n",
            "|    explained_variance | -0.0989  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | -0.0274  |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 4.85e-05 |\n",
            "------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 9     |\n",
            "|    iterations      | 2800  |\n",
            "|    time_elapsed    | 1492  |\n",
            "|    total_timesteps | 14000 |\n",
            "------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 9        |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 1504     |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.3     |\n",
            "|    explained_variance | 0.0138   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | -0.0864  |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.000463 |\n",
            "------------------------------------\n",
            "Eval num_timesteps=15000, episode_reward=-14.99 +/- 20.44\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -15      |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 15000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.29    |\n",
            "|    explained_variance | 0.228    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | 0.028    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 4.65e-05 |\n",
            "------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 9     |\n",
            "|    iterations      | 3000  |\n",
            "|    time_elapsed    | 1599  |\n",
            "|    total_timesteps | 15000 |\n",
            "------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 9        |\n",
            "|    iterations         | 3100     |\n",
            "|    time_elapsed       | 1610     |\n",
            "|    total_timesteps    | 15500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.29    |\n",
            "|    explained_variance | -31.4    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3099     |\n",
            "|    policy_loss        | -0.0989  |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.00121  |\n",
            "------------------------------------\n",
            "Eval num_timesteps=16000, episode_reward=-8.29 +/- 14.23\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -8.29    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.29    |\n",
            "|    explained_variance | 0.0851   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | -0.0696  |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.00029  |\n",
            "------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 9     |\n",
            "|    iterations      | 3200  |\n",
            "|    time_elapsed    | 1707  |\n",
            "|    total_timesteps | 16000 |\n",
            "------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 9        |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 1720     |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.31    |\n",
            "|    explained_variance | -13.2    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | 0.00927  |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 9.86e-05 |\n",
            "------------------------------------\n",
            "Eval num_timesteps=17000, episode_reward=-28.08 +/- 5.21\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -28.1    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 17000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.31    |\n",
            "|    explained_variance | -0.177   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | 0.0351   |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 5.45e-05 |\n",
            "------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 9     |\n",
            "|    iterations      | 3400  |\n",
            "|    time_elapsed    | 1813  |\n",
            "|    total_timesteps | 17000 |\n",
            "------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 9        |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 1825     |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.31    |\n",
            "|    explained_variance | 0.02     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | -0.0755  |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.00035  |\n",
            "------------------------------------\n",
            "Eval num_timesteps=18000, episode_reward=-93.27 +/- 0.60\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -93.3    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.32    |\n",
            "|    explained_variance | 0.285    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | -0.0237  |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 6.14e-05 |\n",
            "------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 9     |\n",
            "|    iterations      | 3600  |\n",
            "|    time_elapsed    | 1920  |\n",
            "|    total_timesteps | 18000 |\n",
            "------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 9        |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 1932     |\n",
            "|    total_timesteps    | 18500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.33    |\n",
            "|    explained_variance | -0.8     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | 0.107    |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.000794 |\n",
            "------------------------------------\n",
            "Eval num_timesteps=19000, episode_reward=-24.28 +/- 15.56\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -24.3    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 19000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.34    |\n",
            "|    explained_variance | -50      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3799     |\n",
            "|    policy_loss        | -0.0364  |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.000119 |\n",
            "------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 9     |\n",
            "|    iterations      | 3800  |\n",
            "|    time_elapsed    | 2027  |\n",
            "|    total_timesteps | 19000 |\n",
            "------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 9        |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 2039     |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.34    |\n",
            "|    explained_variance | -1.39    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | -0.0295  |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 6.71e-05 |\n",
            "------------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=-30.86 +/- 6.02\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 1e+03    |\n",
            "|    mean_reward        | -30.9    |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.35    |\n",
            "|    explained_variance | 0.464    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | -0.0177  |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 2.43e-05 |\n",
            "------------------------------------\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 9     |\n",
            "|    iterations      | 4000  |\n",
            "|    time_elapsed    | 2134  |\n",
            "|    total_timesteps | 20000 |\n",
            "------------------------------\n",
            "Training finished.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Starting training on {ENV_ID} for {TOTAL_TIMESTEPS} steps...\")\n",
        "model.learn(total_timesteps=TOTAL_TIMESTEPS, callback=callbacks_list)\n",
        "print(\"Training finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0B6GJF7nKwa"
      },
      "source": [
        "# Save and Reload Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C-kir3YonJ4Z",
        "outputId": "5f2a918c-e1ba-469a-fa31-d6e0179e1ce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to: Training/Saved Models\n"
          ]
        }
      ],
      "source": [
        "model.save(SAVE_PATH)\n",
        "print(f\"Model saved to: {SAVE_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vRJiYTgznVZ4"
      },
      "outputs": [],
      "source": [
        "del model\n",
        "del env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eHJsAOCmnXq_"
      },
      "outputs": [],
      "source": [
        "env_test = DummyVecEnv([lambda: gym.make(ENV_ID, render_mode=\"rgb_array\")])\n",
        "model = A2C.load(SAVE_PATH, env_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTWjbn_fnZZ3"
      },
      "source": [
        "# Evaluate and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QwQDa3YYnYtc"
      },
      "outputs": [],
      "source": [
        "print(\"\\nEvaluating policy...\")\n",
        "mean_reward, std_reward = evaluate_policy(model, env_test, n_eval_episodes=5, render=False)\n",
        "print(f\"Mean reward over 5 episodes: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iZnVAEQ-ngsL"
      },
      "outputs": [],
      "source": [
        "env_render = gym.make(ENV_ID, render_mode=\"human\")\n",
        "obs, info = env_render.reset()\n",
        "\n",
        "print(\"\\nStarting manual test run (close window to stop)...\")\n",
        "for step in range(2000): # Run for max 2000 steps\n",
        "    action, _states = model.predict(obs, deterministic=True)\n",
        "    obs, rewards, terminated, truncated, info = env_render.step(action)\n",
        "\n",
        "    if terminated or truncated:\n",
        "        obs, info = env_render.reset()\n",
        "\n",
        "env_render.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}